{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nii_to_tfrecord.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/FR-Schwartz/IDS705_Team10/blob/main/source/explore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"mv72K5zcfAt7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"23ba63f0-554c-49e0-8531-b2be5e67fcb1","executionInfo":{"status":"ok","timestamp":1649401446999,"user_tz":240,"elapsed":6840,"user":{"displayName":"Satvik Kishore","userId":"15380440233410685991"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/MyDrive/; to attempt to forcibly remount, call drive.mount(\"/content/MyDrive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import os\n","import shutil\n","import numpy as np\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","import nibabel as nib\n","drive.mount('/content/MyDrive/')\n","os.chdir('/content/MyDrive/MyDrive/IDS705_Final') #change to file path on your disk"]},{"cell_type":"code","source":["#Change subfolder id to checkout different images\n","subfolders = os.listdir(\"Data/Train\")\n","print(\"Number of subfolders:\", len(subfolders))"],"metadata":{"id":"i_uNPTZuglX1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"27f818d5-a541-4f0f-90bc-99303ae68f70","executionInfo":{"status":"ok","timestamp":1649401447121,"user_tz":240,"elapsed":127,"user":{"displayName":"Satvik Kishore","userId":"15380440233410685991"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of subfolders: 1251\n"]}]},{"cell_type":"code","source":["#Helper Functions to convert nii files to tfrecords\n","def float_feature(value):\n","  return tf.train.Feature(float_list = tf.train.FloatList(value = value))\n","\n","def int64_feature(value):\n","  return tf.train.Feature(int64_list = tf.train.Int64List(value = value))\n","\n","def load_one_sample(image_path):\n","  t1 = nib.load(image_path + \"_t1.nii.gz\").get_fdata()\n","  t2 = nib.load(image_path + \"_t2.nii.gz\").get_fdata()\n","  t1ce = nib.load(image_path + \"_t1ce.nii.gz\").get_fdata()\n","  flair = nib.load(image_path + \"_flair.nii.gz\").get_fdata()\n","  image = np.stack([t1, t2, t1ce, flair], 3)\n","  label = nib.load(image_path + \"_seg.nii.gz\").get_fdata().astype(int)\n","  return image, label\n","\n","def create_example(image_path):\n","  image, label = load_one_sample(image_path)\n","  image, label = image.ravel(), label.ravel()\n","  feature = {'image': float_feature(image),\n","             'label': int64_feature(label)}\n","  example = tf.train.Example(features = tf.train.Features(feature = feature))\n","  return example\n","\n","#Use this to load data from record to runtime in the form of x=image , y=segmentation_class\n","def parse_tfrecord(example):\n","  feature = {'image': tf.io.FixedLenFeature([240, 240, 155, 4], tf.float32),\n","             'label': tf.io.FixedLenFeature([240, 240, 155], tf.int64)}\n","  parsed_example = tf.io.parse_single_example(example, feature)\n","  return parsed_example"],"metadata":{"id":"g3r-EJ7KftHK","executionInfo":{"status":"ok","timestamp":1649401490552,"user_tz":240,"elapsed":96,"user":{"displayName":"Satvik Kishore","userId":"15380440233410685991"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#This cell runs conversions to tfrecord one by one. Takes like 4 hrs\n","# for sf in subfolders:\n","#   train_writer = tf.io.TFRecordWriter(f'/content/MyDrive/MyDrive/IDS705_Final/Data/train_tf/{sf}.tfrecord')\n","#   example = create_example(f'Data/Train/{sf}/{sf}')\n","#   train_writer.write(example.SerializeToString())\n","#   train_writer.close()"],"metadata":{"id":"L-c4RXA1_VTH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#dataset = tf.data.Dataset.list_files(f'/content/MyDrive/MyDrive/IDS705_Final/Data/train_tf/*.tfrecord')\n","dataset = tf.data.TFRecordDataset(\n","    [f'/content/MyDrive/MyDrive/IDS705_Final/Data/train_tf/{sf}.tfrecord' for sf in subfolders],\n","    compression_type=None,\n","    buffer_size=None,\n","    num_parallel_reads=None,\n","    name=None\n",")"],"metadata":{"id":"DFhN3fzA07M9","executionInfo":{"status":"ok","timestamp":1649401214134,"user_tz":240,"elapsed":2783,"user":{"displayName":"Satvik Kishore","userId":"15380440233410685991"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def get_image_and_label(features):\n","  image, label = features['image'], features['label']\n","  return image, label\n","\n","def get_image_and_label_auto(features):\n","  image, label = features['image'], features['image']\n","  return image, label\n","\n","def get_dataset(tfrecord_names):\n","  dataset = (tf.data.TFRecordDataset(tfrecord_names)\n","             .map(parse_tfrecord)\n","             .map(get_image_and_label))\n","\n","  return dataset\n","  \n","sf=subfolders[0]\n","dataset = get_dataset([f'/content/MyDrive/MyDrive/IDS705_Final/Data/train_tf/{sf}.tfrecord' for sf in subfolders])\n","#dataset = get_dataset(f'/content/MyDrive/MyDrive/IDS705_Final/Data/train_tf/{sf}.tfrecord')"],"metadata":{"id":"Zd-VGSqR8lne","executionInfo":{"status":"ok","timestamp":1649401560729,"user_tz":240,"elapsed":199,"user":{"displayName":"Satvik Kishore","userId":"15380440233410685991"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["dataset = get_dataset([f'/content/MyDrive/MyDrive/IDS705_Final/Data/train_tf/{sf}.tfrecord' for sf in subfolders]).batch(1)\n"],"metadata":{"id":"nglGGX-b_YyX","executionInfo":{"status":"ok","timestamp":1649401603236,"user_tz":240,"elapsed":236,"user":{"displayName":"Satvik Kishore","userId":"15380440233410685991"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#A starting point for how the first half of the U of the  Tensorflow model will look like\n","def gen_model():\n","    input_layer = tf.keras.layers.Input(shape=(240,240,155,4)) \n","    x = tf.keras.layers.Conv3D(4, 5, strides=(2,2,2), activation='relu', padding='same')(input_layer) #120, 120, 78\n","    x = tf.keras.layers.Conv3D(8, 5, strides=(2,2,2), activation='relu', padding='same')(x) #60, 60, 39\n","    x = tf.keras.layers.Conv3D(16, 5, strides=(2,2,2), activation='relu', padding='same')(x) #30, 30, 20\n","    x = tf.keras.layers.Conv3D(32, 3, strides=(2,2,2), activation='relu', padding='same')(x) #15, 15, 10\n","    x = tf.keras.layers.Conv3D(64, 3, strides=(2,2,2), activation='relu', padding='same')(x) #8, 8, 5\n","    x = tf.keras.layers.Conv3D(128, 3, strides=(2,2,2), activation='relu', padding='same')(x) #4, 4, 3 \n","    x = tf.keras.layers.Conv3D(256, 2, strides=(2,2,2), activation='relu', padding='same')(x) #2, 2, 2   This is the bottom of the \"U\"\n","    x = tf.keras.layers.Conv3DTranspose(128, 2, strides=(2,2,2), activation='relu', padding='same')(x) #4, 4, 4\n","    x = x[:,:,:,0:3,:] #4, 4, 3\n","    x = tf.keras.layers.Conv3DTranspose(64, 3, strides=(2,2,2), activation='relu', padding='same')(x) #8, 8, 6\n","    x = x[:,:,:,0:5,:] #8, 8, 5\n","    x = tf.keras.layers.Conv3DTranspose(64, 3, strides=(2,2,2), activation='relu', padding='same')(x) #16, 16, 12\n","    x = x[:,0:15,0:15,0:10,:] #15, 15, 10\n","    x = tf.keras.layers.Conv3DTranspose(64, 3, strides=(2,2,2), activation='relu', padding='same')(x) #16, 16, 12\n","    x = x[:,0:15,0:15,0:10,:] #15, 15, 10\n","\n","    full_model = tf.keras.Model(inputs=input_layer, outputs=x)\n","    return full_model\n","\n","model = gen_model()\n","model.summary()\n","batch_size = 16\n","n_epochs = 15\n","lr = 1e-3\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy',metrics=['acc'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5ZHMrdN8VEg","outputId":"3be107ca-4a83-4252-ff0e-ca580a1d2b1b","executionInfo":{"status":"ok","timestamp":1649401657391,"user_tz":240,"elapsed":932,"user":{"displayName":"Satvik Kishore","userId":"15380440233410685991"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 240, 240, 155, 4  0         \n","                             )]                                  \n","                                                                 \n"," conv3d_7 (Conv3D)           (None, 120, 120, 78, 4)   2004      \n","                                                                 \n"," conv3d_8 (Conv3D)           (None, 60, 60, 39, 8)     4008      \n","                                                                 \n"," conv3d_9 (Conv3D)           (None, 30, 30, 20, 16)    16016     \n","                                                                 \n"," conv3d_10 (Conv3D)          (None, 15, 15, 10, 32)    13856     \n","                                                                 \n"," conv3d_11 (Conv3D)          (None, 8, 8, 5, 64)       55360     \n","                                                                 \n"," conv3d_12 (Conv3D)          (None, 4, 4, 3, 128)      221312    \n","                                                                 \n"," conv3d_13 (Conv3D)          (None, 2, 2, 2, 256)      262400    \n","                                                                 \n"," conv3d_transpose_4 (Conv3DT  (None, 4, 4, 4, 128)     262272    \n"," ranspose)                                                       \n","                                                                 \n"," tf.__operators__.getitem_4   (None, 4, 4, 3, 128)     0         \n"," (SlicingOpLambda)                                               \n","                                                                 \n"," conv3d_transpose_5 (Conv3DT  (None, 8, 8, 6, 64)      221248    \n"," ranspose)                                                       \n","                                                                 \n"," tf.__operators__.getitem_5   (None, 8, 8, 5, 64)      0         \n"," (SlicingOpLambda)                                               \n","                                                                 \n"," conv3d_transpose_6 (Conv3DT  (None, 16, 16, 10, 64)   110656    \n"," ranspose)                                                       \n","                                                                 \n"," tf.__operators__.getitem_6   (None, 15, 15, 10, 64)   0         \n"," (SlicingOpLambda)                                               \n","                                                                 \n"," conv3d_transpose_7 (Conv3DT  (None, 30, 30, 20, 64)   110656    \n"," ranspose)                                                       \n","                                                                 \n"," tf.__operators__.getitem_7   (None, 15, 15, 10, 64)   0         \n"," (SlicingOpLambda)                                               \n","                                                                 \n","=================================================================\n","Total params: 1,279,788\n","Trainable params: 1,279,788\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#A starting point for how out Tensorflow model will look like\n","def gen_model():\n","    input_layer = tf.keras.layers.Input(shape=(240,240,155,4)) \n","    x = tf.keras.layers.Conv3D(1, 5, strides=(1,1,1), activation='relu', padding='same')(input_layer) \n","    full_model = tf.keras.Model(inputs=input_layer, outputs=x)\n","    return full_model\n","\n","model = gen_model()\n","model.summary()\n","batch_size = 16\n","n_epochs = 15\n","lr = 1e-3\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy',metrics=['acc'])\n","model.fit(dataset)"],"metadata":{"id":"SZZj4_h3_MyB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.predict(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"id":"6E_kF-yjBOHV","executionInfo":{"status":"error","timestamp":1649401998131,"user_tz":240,"elapsed":8116,"user":{"displayName":"Satvik Kishore","userId":"15380440233410685991"}},"outputId":"8b45920c-b595-49f2-9e94-357e87c1a868"},"execution_count":19,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-c36db47ae633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1980\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1983\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}