{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto_encoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FR-Schwartz/IDS705_Team10/blob/main/10/auto_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xoc6oxNcS8hI",
        "outputId": "f3cf0400-ccd4-4af1-bb98-a8e7220ae5c4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Input"
      ],
      "metadata": {
        "id": "IgfTF6oNTCYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwgllL9BZzEb",
        "outputId": "33ed564c-0648-4eef-a8c8-e811ff020e45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/MyDrive/; to attempt to forcibly remount, call drive.mount(\"/content/MyDrive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pickle\n",
        "import tensorflow_gcs_config\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import nibabel as nib\n",
        "import tensorflow_hub as hub\n",
        "drive.mount('/content/MyDrive/')\n",
        "os.chdir('/content/MyDrive/MyDrive/IDS705_Final') #change to file path on your disk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper Functions\n",
        "def parse_tfrecord(example):\n",
        "  \"\"\"\n",
        "  This function helps in parsing tfrecord files when creating a TF Dataset object\n",
        "  \"\"\"\n",
        "  feature = {'image': tf.io.FixedLenFeature([240, 240, 155, 4], tf.float32),\n",
        "             'label': tf.io.FixedLenFeature([240, 240, 155], tf.int64)}\n",
        "  parsed_example = tf.io.parse_single_example(example, feature)\n",
        "  return parsed_example\n",
        "\n",
        "def get_image_and_label(features):\n",
        "  \"\"\"\n",
        "  Extract Image and Label Object from tfrecord files\n",
        "  \"\"\"\n",
        "  image, label = features['image'], features['label']\n",
        "  return image, label\n",
        "\n",
        "def get_image_and_label_auto(features):\n",
        "  \"\"\"\n",
        "  Extract Image and Label Object from tfrecord files\n",
        "  \"\"\"\n",
        "  image = features['image']\n",
        "  return image, image\n",
        "\n",
        "def get_dataset(tfrecord_names):\n",
        "  \"\"\"\n",
        "  Create TF dataset files that can be fed into model functions\n",
        "  \"\"\"\n",
        "  dataset = (tf.data.TFRecordDataset(tfrecord_names)\n",
        "             .map(parse_tfrecord)\n",
        "             .map(get_image_and_label_auto))\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "AIEqR7NMZ-9P"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(input_layer):\n",
        "  # Elements in layer represent in this order batchSize, height, width, channels\n",
        "  print(\"*****Encoder*****\", input_layer)\n",
        "\n",
        "  x4 = tf.keras.layers.BatchNormalization()(input_layer)\n",
        "  x4 = tf.keras.layers.Conv3D( 4, 3, strides=(1,1,1), activation='relu', padding='same')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv3D( 4, 3, strides=(1,1,1), activation='relu', padding='same')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "\n",
        "  print(\"x1\", x4.shape)\n",
        "\n",
        "  x8 = tf.keras.layers.Conv3D( 8, 3, strides=(2,2,2), activation='relu', padding='same')(x4)\n",
        "  x8 = tf.keras.layers.BatchNormalization()(x8)\n",
        "  x8 = tf.keras.layers.Conv3D( 8, 3, strides=(1,1,1), activation='relu', padding='same')(x8)\n",
        "  x8 = tf.keras.layers.BatchNormalization()(x8)\n",
        "\n",
        "  print(\"x2\", x8.shape)\n",
        "\n",
        "  x16 = tf.keras.layers.Conv3D(16, 3, strides=(2,2,2), activation='relu', padding='same')(x8)\n",
        "  x16 = tf.keras.layers.BatchNormalization()(x16)\n",
        "  x16 = tf.keras.layers.Conv3D(16, 3, strides=(1,1,1), activation='relu', padding='same')(x16)\n",
        "  x16 = tf.keras.layers.BatchNormalization()(x16)\n",
        "\n",
        "  print(\"x3\", x16.shape)\n",
        "\n",
        "  x32 = tf.keras.layers.Conv3D(32, 3, strides=(2,2,2), activation='relu', padding='same')(x16)\n",
        "  x32 = tf.keras.layers.BatchNormalization()(x32)\n",
        "  x32 = tf.keras.layers.Conv3D(32, 3, strides=(1,1,1), activation='relu', padding='same')(x32)\n",
        "  x32 = tf.keras.layers.BatchNormalization()(x32)\n",
        "\n",
        "  print(\"x4\", x32.shape)\n",
        "\n",
        "  x64 = tf.keras.layers.Conv3D(64, 3, strides=(2,2,2), activation='relu', padding='same')(x32)\n",
        "  x64 = tf.keras.layers.BatchNormalization()(x64)\n",
        "  x64 = tf.keras.layers.Conv3D(64, 3, strides=(1,1,1), activation='relu', padding='same')(x64)\n",
        "  x64 = tf.keras.layers.BatchNormalization()(x64)\n",
        "  \n",
        "  print(\"x5\", x64.shape)\n",
        "\n",
        "  x128 = tf.keras.layers.Conv3D(128, 3, strides=(2,2,2), activation='relu', padding='same')(x64)\n",
        "  x128 = tf.keras.layers.BatchNormalization()(x128)\n",
        "  x128 = tf.keras.layers.Conv3D(128, 3, strides=(1,1,1), activation='relu', padding='same')(x128)\n",
        "  x128 = tf.keras.layers.BatchNormalization()(x128)\n",
        "\n",
        "  print(\"x6\", x128.shape)\n",
        "\n",
        "  return x128\n"
      ],
      "metadata": {
        "id": "xomunduXbdvM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(encoded_layer):\n",
        "  print(\"*****Decoder*****\", encoded_layer)\n",
        "\n",
        "  x64 = tf.keras.layers.Conv3DTranspose(64, 3, strides=(1,1,1), activation='relu')(encoded_layer)\n",
        "  x64 = tf.keras.layers.Conv3DTranspose(64, 3, strides=(2,2,2), activation='relu', padding='same')(x64)\n",
        "  x64 = tf.keras.layers.Cropping3D(cropping=((1,2), (1,2), (1,1)))(x64)\n",
        "  x64 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x64)\n",
        "  print(\"x1\", x64.shape)\n",
        "\n",
        "  \n",
        "  x32 = tf.keras.layers.Conv3DTranspose(32, 3, strides=(1,1,1), activation='relu')(x64)\n",
        "  x32 = tf.keras.layers.Conv3DTranspose(32, 3, strides=(2,2,2), activation='relu', padding='same')(x32)\n",
        "  x32 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x32)\n",
        "  x32 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x32)\n",
        "\n",
        "  print(\"x2\", x32.shape)\n",
        "\n",
        "  x16 = tf.keras.layers.Conv3DTranspose(16, 3, strides=(1,1,1), activation='relu')(x32)\n",
        "  x16 = tf.keras.layers.Conv3DTranspose(16, 3, strides=(2,2,2), activation='relu', padding='same')(x16)\n",
        "  x16 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x16)\n",
        "  x16 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,2)))(x16)\n",
        "\n",
        "  print(\"x4\", x16.shape)\n",
        "\n",
        "  x8 = tf.keras.layers.Conv3DTranspose(8, 3, strides=(1,1,1), activation='relu')(x16)\n",
        "  x8 = tf.keras.layers.Conv3DTranspose(8, 3, strides=(2,2,2), activation='relu', padding='same')(x8)\n",
        "  x8 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x8)\n",
        "  x8 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x8)\n",
        "\n",
        "  print(\"x5\", x8.shape)\n",
        "\n",
        "  x4 = tf.keras.layers.Conv3DTranspose(4, 3, strides=(1,1,1), activation='relu')(x8)\n",
        "  x4 = tf.keras.layers.Conv3DTranspose(4, 3, strides=(2,2,2), activation='relu', padding='same')(x4)\n",
        "  x4 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x4)\n",
        "  x4 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,2)))(x4)\n",
        "\n",
        "\n",
        "\n",
        "  print(\"x6\", x4.shape)\n",
        "\n",
        "  return x4\n",
        "  \n"
      ],
      "metadata": {
        "id": "xfKx3a4mf6wt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Encoder and Deocder layers\n",
        "from keras.models import Model, Input\n",
        "\n",
        "input_layer = tf.keras.layers.Input(shape=(240,240,155,4))\n",
        "e_l = encoder(input_layer)\n",
        "output = decoder(e_l)\n",
        "\n",
        "\n",
        "autoencoder = Model(inputs = input_layer, outputs = output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u0_SCrLis2p",
        "outputId": "eb9fe975-4e69-43ec-dfef-10f0fb5ae278"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****Encoder***** KerasTensor(type_spec=TensorSpec(shape=(None, 240, 240, 155, 4), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n",
            "x1 (None, 240, 240, 155, 4)\n",
            "x2 (None, 120, 120, 78, 8)\n",
            "x3 (None, 60, 60, 39, 16)\n",
            "x4 (None, 30, 30, 20, 32)\n",
            "x5 (None, 15, 15, 10, 64)\n",
            "x6 (None, 8, 8, 5, 128)\n",
            "*****Decoder***** KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 5, 128), dtype=tf.float32, name=None), name='batch_normalization_25/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_25'\")\n",
            "x1 (None, 15, 15, 10, 64)\n",
            "x2 (None, 30, 30, 20, 32)\n",
            "x4 (None, 60, 60, 39, 16)\n",
            "x5 (None, 120, 120, 78, 8)\n",
            "x6 (None, 240, 240, 155, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as k\n",
        "\n",
        "class DiceLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, smooth=1e-6, gama=2):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.name = 'NDL'\n",
        "        self.smooth = smooth\n",
        "        self.gama = gama\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "\n",
        "        inter = k.sum(y_true[:,:,-1]*y_pred[:,:,-1])\n",
        "        return (2*inter + 1)/(k.sum(y_true[:,:,-1]) + k.sum(y_pred[:,:,-1]) + 1)"
      ],
      "metadata": {
        "id": "JAdrUaiPDoDO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=1e-3\n",
        "autoencoder.compile(loss=DiceLoss(), optimizer=tf.keras.optimizers.Adam(learning_rate=lr))\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmgO9tIMnRl_",
        "outputId": "a59af062-3267-4467-95ea-b84c25d1395f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 240, 240, 155, 4  0         \n",
            "                             )]                                  \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 240, 240, 155, 4)  16       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_12 (Conv3D)          (None, 240, 240, 155, 4)  436       \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 240, 240, 155, 4)  16       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_13 (Conv3D)          (None, 240, 240, 155, 4)  436       \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 240, 240, 155, 4)  16       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_14 (Conv3D)          (None, 120, 120, 78, 8)   872       \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 120, 120, 78, 8)  32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_15 (Conv3D)          (None, 120, 120, 78, 8)   1736      \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 120, 120, 78, 8)  32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_16 (Conv3D)          (None, 60, 60, 39, 16)    3472      \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 60, 60, 39, 16)   64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_17 (Conv3D)          (None, 60, 60, 39, 16)    6928      \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 60, 60, 39, 16)   64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_18 (Conv3D)          (None, 30, 30, 20, 32)    13856     \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 30, 30, 20, 32)   128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_19 (Conv3D)          (None, 30, 30, 20, 32)    27680     \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 30, 30, 20, 32)   128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_20 (Conv3D)          (None, 15, 15, 10, 64)    55360     \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 15, 15, 10, 64)   256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_21 (Conv3D)          (None, 15, 15, 10, 64)    110656    \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 15, 15, 10, 64)   256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_22 (Conv3D)          (None, 8, 8, 5, 128)      221312    \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 8, 8, 5, 128)     512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_23 (Conv3D)          (None, 8, 8, 5, 128)      442496    \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 8, 8, 5, 128)     512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_transpose_10 (Conv3D  (None, 10, 10, 7, 64)    221248    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv3d_transpose_11 (Conv3D  (None, 20, 20, 14, 64)   110656    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " cropping3d_10 (Cropping3D)  (None, 17, 17, 12, 64)    0         \n",
            "                                                                 \n",
            " cropping3d_11 (Cropping3D)  (None, 15, 15, 10, 64)    0         \n",
            "                                                                 \n",
            " conv3d_transpose_12 (Conv3D  (None, 17, 17, 12, 32)   55328     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv3d_transpose_13 (Conv3D  (None, 34, 34, 24, 32)   27680     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " cropping3d_12 (Cropping3D)  (None, 32, 32, 22, 32)    0         \n",
            "                                                                 \n",
            " cropping3d_13 (Cropping3D)  (None, 30, 30, 20, 32)    0         \n",
            "                                                                 \n",
            " conv3d_transpose_14 (Conv3D  (None, 32, 32, 22, 16)   13840     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv3d_transpose_15 (Conv3D  (None, 64, 64, 44, 16)   6928      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " cropping3d_14 (Cropping3D)  (None, 62, 62, 42, 16)    0         \n",
            "                                                                 \n",
            " cropping3d_15 (Cropping3D)  (None, 60, 60, 39, 16)    0         \n",
            "                                                                 \n",
            " conv3d_transpose_16 (Conv3D  (None, 62, 62, 41, 8)    3464      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv3d_transpose_17 (Conv3D  (None, 124, 124, 82, 8)  1736      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " cropping3d_16 (Cropping3D)  (None, 122, 122, 80, 8)   0         \n",
            "                                                                 \n",
            " cropping3d_17 (Cropping3D)  (None, 120, 120, 78, 8)   0         \n",
            "                                                                 \n",
            " conv3d_transpose_18 (Conv3D  (None, 122, 122, 80, 4)  868       \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv3d_transpose_19 (Conv3D  (None, 244, 244, 160, 4)  436      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " cropping3d_18 (Cropping3D)  (None, 242, 242, 158, 4)  0         \n",
            "                                                                 \n",
            " cropping3d_19 (Cropping3D)  (None, 240, 240, 155, 4)  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,456\n",
            "Trainable params: 1,328,440\n",
            "Non-trainable params: 1,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Train / Val / Test Split\n",
        "subfolders = os.listdir(\"Data/Train\")\n",
        "np.random.seed(101)\n",
        "split = np.random.choice([\"Train\",\"Val\",\"Test\"], len(subfolders), p=[0.6, 0.2, 0.2])\n",
        "train_ids = [subfolders[i] for i,v in enumerate(split) if v==\"Train\"]\n",
        "val_ids = [subfolders[i] for i,v in enumerate(split) if v==\"Val\"]\n",
        "test_ids = [subfolders[i] for i,v in enumerate(split) if v==\"Test\"]"
      ],
      "metadata": {
        "id": "ejWz28eRImyn"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dataset objects\n",
        "train_dataset = get_dataset([f'Data/train_tf/{sf}.tfrecord' for sf in train_ids])\n",
        "test_dataset = get_dataset([f'Data/train_tf/{sf}.tfrecord' for sf in test_ids])\n",
        "val_dataset = get_dataset([f'Data/train_tf/{sf}.tfrecord' for sf in val_ids])\n",
        "mini_dataset = get_dataset([f'Data/train_tf/{sf}.tfrecord' for sf in subfolders[100:228]])\n",
        "minival_dataset = get_dataset([f'Data/train_tf/{sf}.tfrecord' for sf in subfolders[500:508]])"
      ],
      "metadata": {
        "id": "cYaE9ELQGdoI"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize = 4\n",
        "shufflesize = 8\n",
        "mini_dataset_trainable = mini_dataset.shuffle(shufflesize).batch(batchsize)\n",
        "minival_dataset_validable = minival_dataset.batch(batchsize)\n",
        "train_dataset_trainable = train_dataset.shuffle(shufflesize).batch(batchsize)\n",
        "val_dataset_validable = val_dataset.batch(batchsize)"
      ],
      "metadata": {
        "id": "muk7qrVro3N6"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n"
      ],
      "metadata": {
        "id": "Ep1TreDkQBOs"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "auto_enc = autoencoder.fit(train_dataset_trainable, epochs = epochs, batch_size = 4, shuffle = False, \\\n",
        "                           validation_data=val_dataset_validable, callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n",
        "\n",
        "loss = auto_enc.history['loss']\n",
        "val_loss = auto_enc.history['val_loss']\n",
        "epochs = range(epochs)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'go', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "qyANFfcRpvXs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d92e7e45-ae1e-4044-9f20-95dd8d5f8969"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-93af48dcb552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauto_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_trainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m                            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset_validable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/tmp/autoencoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node 'IteratorGetNext' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-37-f2a8f6b8e35a>\", line 2, in <module>\n      auto_enc = autoencoder.fit(train_dataset_trainable, epochs = epochs, batch_size = 4, shuffle = False,validation_data=val_dataset_validable, callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1009, in step_function\n      data = next(iterator)\nNode: 'IteratorGetNext'\nDetected at node 'IteratorGetNext' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-37-f2a8f6b8e35a>\", line 2, in <module>\n      auto_enc = autoencoder.fit(train_dataset_trainable, epochs = epochs, batch_size = 4, shuffle = False,validation_data=val_dataset_validable, callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1009, in step_function\n      data = next(iterator)\nNode: 'IteratorGetNext'\n2 root error(s) found.\n  (0) UNKNOWN:  Data/train_tf/BraTS2021_00350.tfrecord; Input/output error\n\t [[{{node IteratorGetNext}}]]\n\t [[IteratorGetNext/_4]]\n  (1) UNKNOWN:  Data/train_tf/BraTS2021_00350.tfrecord; Input/output error\n\t [[{{node IteratorGetNext}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_11111]"
          ]
        }
      ]
    }
  ]
}